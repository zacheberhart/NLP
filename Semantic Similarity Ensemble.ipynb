{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gc\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from random import sample\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models.fasttext import load_facebook_vectors, load_facebook_model\n",
    "\n",
    "DB_PATH = 'data/db/spotify.db'\n",
    "SEED = 413"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Similarity Ensemble\n",
    "\n",
    "This notebook uses the Semantic Similarity scores generated by several models (BERT, FastText, USE, Word2Vec, and GLoVe) and evaluates which scores are the most relevant for this use case (cleaning search results of user-generated content, playlists).\n",
    "\n",
    "To do this, I manually labeled a small sample (not a completely random sample as most of the search results are good so there isn't much balance to the data) and used a Random Forest and Linear Regression to assess feature importance and coefficients to see which models were the most accurate.\n",
    "\n",
    "In the end, I use the RF similarity scores to clean / filter my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' I originally had labeled data with different special charcter rules, so\n",
    "first I need to merge it back together. There were about 1.2k labels in the original dataset.'''\n",
    "\n",
    "df = pd.read_feather('final_uniq_plns_WITH_BERT&USE&W2V&GLOVE&FT')\n",
    "labels = pd.read_csv('existing_labels_before_new_spec_char_rules.csv', encoding='iso-8859-1')\n",
    "labels['lookup'] = labels['query'].astype(str) + '_____' + labels['search_rank'].astype(str)\n",
    "df['lookup'] = df['query'].astype(str) + '_____' + df['search_rank'].astype(str)\n",
    "df = deepcopy(df.merge(labels[['lookup', 'SCORE']], on = 'lookup', how = 'left'))\n",
    "df.drop('lookup', axis = 1, inplace = True)\n",
    "del labels\n",
    "df.reset_index(drop = True).to_feather('final_uniq_plns_WITH_BERT&USE&W2V&GLOVE&FT_&_init-score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Some More\n",
    "\n",
    "Although I'm sure that the previous labels would still be valid with the new special character rules, I'd still like to make sure. So I'm adding about 500 more labels (~50% more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('final_uniq_plns_WITH_BERT&USE&W2V&GLOVE&FT_&_init-score')\n",
    "\n",
    "# remove data we already have labels for\n",
    "df = deepcopy(df[df.SCORE.isnull()].reset_index(drop = True))\n",
    "df.drop('SCORE', 1, inplace = True)\n",
    "\n",
    "# get standardized similarity scores\n",
    "scaler = StandardScaler()\n",
    "stzd_X = scaler.fit_transform(df.iloc[:,4:-1])\n",
    "\n",
    "# add standardized similarity to main df\n",
    "sdf = pd.DataFrame(stzd_X, columns = df.columns[4:-1].tolist())\n",
    "df[sdf.columns.tolist()] = deepcopy(sdf)\n",
    "\n",
    "# add an avg of all overall similarity scores for each model\n",
    "df['avg_all'] = df[[\n",
    "    'bert_overall_similarity',\n",
    "    'use_transformer_overall_similarity',\n",
    "    'use_dan_overall_similarity',\n",
    "    'glove_overall_similarity',\n",
    "    'ft_wiki_overall_similarity',\n",
    "    'ft_crawl_overall_similarity']].mean(1)\n",
    "\n",
    "# export sample to label\n",
    "tdf = deepcopy(df[['query', 'track_id', 'playlist_name', 'search_rank', 'avg_all']])\n",
    "tdf[tdf.avg_all < 0].sample(50000).to_csv('new_plns_to_label_new_spec_char.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Old & New Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load new labels and join with data\n",
    "labels = pd.read_csv('addl_labels_after_spec_char_update.csv', encoding='iso-8859-1')\n",
    "labels.index = labels['index']\n",
    "labels.drop('index', axis = 1, inplace = True)\n",
    "joined = df.join(labels[['SCORE', 'playlist_name']], rsuffix = '_TEMP').dropna()\n",
    "joined = deepcopy(joined[['query', 'track_id', 'playlist_name', 'search_rank', 'SCORE']])\n",
    "\n",
    "# append old labels\n",
    "old_labels = pd.read_feather('final_uniq_plns_WITH_BERT&USE&W2V&GLOVE&FT_&_init-score').dropna()\n",
    "joined = deepcopy(joined.append(old_labels[['query', 'track_id', 'playlist_name', 'search_rank', 'SCORE']]))\n",
    "\n",
    "''' join with existing labels from previous dataset'''\n",
    "labels = deepcopy(joined)\n",
    "df = pd.read_feather('final_uniq_plns_WITH_BERT&USE&W2V&GLOVE&FT')\n",
    "labels['lookup'] = labels['query'].astype(str) + '_____' + labels['search_rank'].astype(str)\n",
    "df['lookup'] = df['query'].astype(str) + '_____' + df['search_rank'].astype(str)\n",
    "df = deepcopy(df.merge(labels[['lookup', 'SCORE']], on = 'lookup', how = 'left'))\n",
    "df.drop('lookup', axis = 1, inplace = True)\n",
    "del labels\n",
    "df.reset_index(drop = True).to_feather('final_uniq_plns_WITH_BERT&USE&W2V&GLOVE&FT_&_init&new-score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('final_uniq_plns_WITH_BERT&USE&W2V&GLOVE&FT_&_init&new-score')\n",
    "\n",
    "# get standardized similarity scores\n",
    "scaler = StandardScaler()\n",
    "stzd_X = scaler.fit_transform(df.iloc[:,4:-1])\n",
    "\n",
    "# add standardized similarity to main df\n",
    "sdf = pd.DataFrame(stzd_X, columns = df.columns[4:-1].tolist())\n",
    "df[sdf.columns.tolist()] = deepcopy(sdf)\n",
    "\n",
    "# add an avg of all overall similarity scores for each model\n",
    "df['avg_all'] = df[[\n",
    "    'bert_overall_similarity',\n",
    "    'use_transformer_overall_similarity',\n",
    "    'use_dan_overall_similarity',\n",
    "    'glove_overall_similarity',\n",
    "    'ft_wiki_overall_similarity',\n",
    "    'ft_crawl_overall_similarity']].mean(1)\n",
    "\n",
    "# export\n",
    "df.rename(columns = {'SCORE': 'score'}, inplace = True)\n",
    "df.reset_index(drop = True).to_feather('final_full_standardized_uniq_plns_with_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data WITH LABELS ONLY\n",
    "df = pd.read_feather('final_full_standardized_uniq_plns_with_labels').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>track_id</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>search_rank</th>\n",
       "      <th>bert_max_pln_similarity</th>\n",
       "      <th>bert_avg_pln_similarity</th>\n",
       "      <th>bert_max_token_max_similarity</th>\n",
       "      <th>bert_avg_token_max_similarity</th>\n",
       "      <th>bert_overall_avg_max_similarity</th>\n",
       "      <th>bert_overall_avg_avg_similarity</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_wiki_overall_similarity</th>\n",
       "      <th>ft_crawl_max_pln_similarity</th>\n",
       "      <th>ft_crawl_avg_pln_similarity</th>\n",
       "      <th>ft_crawl_max_token_max_similarity</th>\n",
       "      <th>ft_crawl_avg_token_max_similarity</th>\n",
       "      <th>ft_crawl_overall_avg_max_similarity</th>\n",
       "      <th>ft_crawl_overall_avg_avg_similarity</th>\n",
       "      <th>ft_crawl_overall_similarity</th>\n",
       "      <th>score</th>\n",
       "      <th>avg_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1030145</th>\n",
       "      <td>running</td>\n",
       "      <td>1MB60Ingbxmdukc2wq8b2G</td>\n",
       "      <td>remix hits</td>\n",
       "      <td>464</td>\n",
       "      <td>-1.954781</td>\n",
       "      <td>-1.765774</td>\n",
       "      <td>-3.86681</td>\n",
       "      <td>-3.552363</td>\n",
       "      <td>-3.136856</td>\n",
       "      <td>-2.890563</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.742427</td>\n",
       "      <td>-0.902903</td>\n",
       "      <td>-0.834854</td>\n",
       "      <td>-2.368756</td>\n",
       "      <td>-2.314524</td>\n",
       "      <td>-1.824455</td>\n",
       "      <td>-1.790294</td>\n",
       "      <td>-1.818691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.62401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           query                track_id playlist_name  search_rank  \\\n",
       "1030145  running  1MB60Ingbxmdukc2wq8b2G    remix hits          464   \n",
       "\n",
       "         bert_max_pln_similarity  bert_avg_pln_similarity  \\\n",
       "1030145                -1.954781                -1.765774   \n",
       "\n",
       "         bert_max_token_max_similarity  bert_avg_token_max_similarity  \\\n",
       "1030145                       -3.86681                      -3.552363   \n",
       "\n",
       "         bert_overall_avg_max_similarity  bert_overall_avg_avg_similarity  \\\n",
       "1030145                        -3.136856                        -2.890563   \n",
       "\n",
       "         ...  ft_wiki_overall_similarity  ft_crawl_max_pln_similarity  \\\n",
       "1030145  ...                   -2.742427                    -0.902903   \n",
       "\n",
       "         ft_crawl_avg_pln_similarity  ft_crawl_max_token_max_similarity  \\\n",
       "1030145                    -0.834854                          -2.368756   \n",
       "\n",
       "         ft_crawl_avg_token_max_similarity  \\\n",
       "1030145                          -2.314524   \n",
       "\n",
       "         ft_crawl_overall_avg_max_similarity  \\\n",
       "1030145                            -1.824455   \n",
       "\n",
       "         ft_crawl_overall_avg_avg_similarity  ft_crawl_overall_similarity  \\\n",
       "1030145                            -1.790294                    -1.818691   \n",
       "\n",
       "         score  avg_all  \n",
       "1030145    0.0 -2.62401  \n",
       "\n",
       "[1 rows x 49 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    758\n",
       "0.0    758\n",
       "0.5    143\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['query', 'track_id', 'playlist_name', 'search_rank'], axis = 1, inplace = True)\n",
    "df = df[[col for col in df.columns if col != 'score'] + ['score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert_max_pln_similarity</th>\n",
       "      <th>bert_avg_pln_similarity</th>\n",
       "      <th>bert_max_token_max_similarity</th>\n",
       "      <th>bert_avg_token_max_similarity</th>\n",
       "      <th>bert_overall_avg_max_similarity</th>\n",
       "      <th>bert_overall_avg_avg_similarity</th>\n",
       "      <th>bert_overall_similarity</th>\n",
       "      <th>use_transformer_max_pln_similarity</th>\n",
       "      <th>use_transformer_avg_pln_similarity</th>\n",
       "      <th>use_transformer_max_token_max_similarity</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_wiki_overall_similarity</th>\n",
       "      <th>ft_crawl_max_pln_similarity</th>\n",
       "      <th>ft_crawl_avg_pln_similarity</th>\n",
       "      <th>ft_crawl_max_token_max_similarity</th>\n",
       "      <th>ft_crawl_avg_token_max_similarity</th>\n",
       "      <th>ft_crawl_overall_avg_max_similarity</th>\n",
       "      <th>ft_crawl_overall_avg_avg_similarity</th>\n",
       "      <th>ft_crawl_overall_similarity</th>\n",
       "      <th>avg_all</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>-1.019679</td>\n",
       "      <td>-0.856142</td>\n",
       "      <td>-3.372802</td>\n",
       "      <td>-3.094917</td>\n",
       "      <td>-2.213858</td>\n",
       "      <td>-2.006395</td>\n",
       "      <td>-2.135536</td>\n",
       "      <td>-1.813332</td>\n",
       "      <td>-1.725463</td>\n",
       "      <td>-3.611603</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.657022</td>\n",
       "      <td>-0.882583</td>\n",
       "      <td>-0.813542</td>\n",
       "      <td>-2.614015</td>\n",
       "      <td>-2.555157</td>\n",
       "      <td>-1.931932</td>\n",
       "      <td>-1.900680</td>\n",
       "      <td>-1.928271</td>\n",
       "      <td>-2.272804</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-0.397358</td>\n",
       "      <td>-0.250772</td>\n",
       "      <td>-1.150517</td>\n",
       "      <td>-1.037107</td>\n",
       "      <td>-0.792924</td>\n",
       "      <td>-0.645239</td>\n",
       "      <td>-0.726902</td>\n",
       "      <td>-1.040763</td>\n",
       "      <td>-0.938433</td>\n",
       "      <td>-2.317882</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.237054</td>\n",
       "      <td>-1.055477</td>\n",
       "      <td>-0.994882</td>\n",
       "      <td>-2.684592</td>\n",
       "      <td>-2.624402</td>\n",
       "      <td>-2.090746</td>\n",
       "      <td>-2.063793</td>\n",
       "      <td>-2.090193</td>\n",
       "      <td>-1.843457</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>-2.362173</td>\n",
       "      <td>-2.162070</td>\n",
       "      <td>-5.422951</td>\n",
       "      <td>-4.993332</td>\n",
       "      <td>-4.110228</td>\n",
       "      <td>-3.822986</td>\n",
       "      <td>-4.015490</td>\n",
       "      <td>-1.640258</td>\n",
       "      <td>-1.549150</td>\n",
       "      <td>-3.585043</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.336442</td>\n",
       "      <td>-1.816045</td>\n",
       "      <td>-1.792604</td>\n",
       "      <td>-4.015129</td>\n",
       "      <td>-3.929839</td>\n",
       "      <td>-3.296856</td>\n",
       "      <td>-3.302553</td>\n",
       "      <td>-3.319907</td>\n",
       "      <td>-3.309651</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bert_max_pln_similarity  bert_avg_pln_similarity  \\\n",
       "245                -1.019679                -0.856142   \n",
       "249                -0.397358                -0.250772   \n",
       "251                -2.362173                -2.162070   \n",
       "\n",
       "     bert_max_token_max_similarity  bert_avg_token_max_similarity  \\\n",
       "245                      -3.372802                      -3.094917   \n",
       "249                      -1.150517                      -1.037107   \n",
       "251                      -5.422951                      -4.993332   \n",
       "\n",
       "     bert_overall_avg_max_similarity  bert_overall_avg_avg_similarity  \\\n",
       "245                        -2.213858                        -2.006395   \n",
       "249                        -0.792924                        -0.645239   \n",
       "251                        -4.110228                        -3.822986   \n",
       "\n",
       "     bert_overall_similarity  use_transformer_max_pln_similarity  \\\n",
       "245                -2.135536                           -1.813332   \n",
       "249                -0.726902                           -1.040763   \n",
       "251                -4.015490                           -1.640258   \n",
       "\n",
       "     use_transformer_avg_pln_similarity  \\\n",
       "245                           -1.725463   \n",
       "249                           -0.938433   \n",
       "251                           -1.549150   \n",
       "\n",
       "     use_transformer_max_token_max_similarity  ...  \\\n",
       "245                                 -3.611603  ...   \n",
       "249                                 -2.317882  ...   \n",
       "251                                 -3.585043  ...   \n",
       "\n",
       "     ft_wiki_overall_similarity  ft_crawl_max_pln_similarity  \\\n",
       "245                   -1.657022                    -0.882583   \n",
       "249                   -2.237054                    -1.055477   \n",
       "251                   -3.336442                    -1.816045   \n",
       "\n",
       "     ft_crawl_avg_pln_similarity  ft_crawl_max_token_max_similarity  \\\n",
       "245                    -0.813542                          -2.614015   \n",
       "249                    -0.994882                          -2.684592   \n",
       "251                    -1.792604                          -4.015129   \n",
       "\n",
       "     ft_crawl_avg_token_max_similarity  ft_crawl_overall_avg_max_similarity  \\\n",
       "245                          -2.555157                            -1.931932   \n",
       "249                          -2.624402                            -2.090746   \n",
       "251                          -3.929839                            -3.296856   \n",
       "\n",
       "     ft_crawl_overall_avg_avg_similarity  ft_crawl_overall_similarity  \\\n",
       "245                            -1.900680                    -1.928271   \n",
       "249                            -2.063793                    -2.090193   \n",
       "251                            -3.302553                    -3.319907   \n",
       "\n",
       "      avg_all  score  \n",
       "245 -2.272804    0.0  \n",
       "249 -1.843457    0.0  \n",
       "251 -3.309651    0.0  \n",
       "\n",
       "[3 rows x 45 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(df) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'rf': [], 'lr': []}\n",
    "\n",
    "for _ in range(500):\n",
    "    \n",
    "    if _%10==0: print(f'Iter: {_}')\n",
    "    \n",
    "    # shuffle data\n",
    "    df = deepcopy(df.sample(len(df)).reset_index(drop = True))\n",
    "    \n",
    "    # set train/test\n",
    "    X_train = df.iloc[:n_train,:-1].values\n",
    "    y_train = df.iloc[:n_train,-1].values\n",
    "    X_test = df.iloc[n_train:,:-1].values\n",
    "    y_test = df.iloc[n_train:,-1].values\n",
    "    \n",
    "    # init\n",
    "    #rf = RandomForestRegressor(random_state = SEED, n_estimators = 1000)\n",
    "    \n",
    "    # FIRST GRID SEARCH\n",
    "    rf = RandomForestRegressor(\n",
    "        bootstrap = True,\n",
    "        max_depth = 24,\n",
    "        max_features = 'sqrt',\n",
    "        max_leaf_nodes = None,\n",
    "        min_impurity_decrease = 0.0,\n",
    "        min_impurity_split = None,\n",
    "        min_samples_leaf = 3,\n",
    "        min_samples_split = 2,\n",
    "        min_weight_fraction_leaf = 0.0,\n",
    "        n_estimators = 290,\n",
    "        #random_state = SEED,\n",
    "    )\n",
    "    \n",
    "#     # SECOND GRID SEARCH\n",
    "#     rf = RandomForestRegressor(\n",
    "#         bootstrap = True,\n",
    "#         criterion = 'mse',\n",
    "#         max_depth = 22,\n",
    "#         max_features = 'sqrt',\n",
    "#         max_leaf_nodes = None,\n",
    "#         min_impurity_decrease = 0.0,\n",
    "#         min_impurity_split = None,\n",
    "#         min_samples_leaf = 3,\n",
    "#         min_samples_split = 2,\n",
    "#         min_weight_fraction_leaf = 0.0,\n",
    "#         n_estimators = 295,\n",
    "#         #random_state = SEED,\n",
    "#     )\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    # fit\n",
    "    rf.fit(X_train, y_train)\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # save results\n",
    "    results['rf'].append(float(mse(y_true = y_test, y_pred = rf.predict(X_test)) ** 0.5))\n",
    "    results['lr'].append(float(mse(y_true = y_test, y_pred = lr.predict(X_test)) ** 0.5))\n",
    "    \n",
    "    del X_train, y_train, X_test, y_test, rf, lr\n",
    "    gc.collect()\n",
    "    \n",
    "    print('done.')\n",
    "    \n",
    "# build df\n",
    "results = pd.DataFrame({'rf': results['rf'], 'lr': results['lr']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    500.000000\n",
       "mean       0.293502\n",
       "std        0.013731\n",
       "min        0.253555\n",
       "25%        0.284499\n",
       "50%        0.293820\n",
       "75%        0.302505\n",
       "max        0.333928\n",
       "Name: rf, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIRST GRID SEARCH\n",
    "results.rf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a428ddac8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEwRJREFUeJzt3X2QXXV9x/H310QedyBAdEsTdFFSK7BWzJZSrc5dkJEHBRyloqjBoZPSUmVqnBJKZ+h0ygzq4NNonWaKmo4dFupIoTwoNM3q0BLaRJAAEUHMIA8FHQG7gA9rv/3jnp1cQsjuvefe3cOP92vmzt5zzu+c89ns3s89e869N5GZSJLK9ZKFDiBJGiyLXpIKZ9FLUuEsekkqnEUvSYWz6CWpcBa9JBXOopekwln0klS4xQsdAGDp0qU5MjLCU089xb777rvQcZ7DXN1pYq4mZgJzdctcz7Zly5afZObLZh2YmQt+W7lyZWZmbty4MZvIXN1pYq4mZso0V7fM9WzA5pxDx3rqRpIKZ9FLUuFmLfqI+FJEPBYRd3bM+2REfC8i7oiIqyJiSceyCyLivoi4JyLeNqjgkqS5mcsR/VeAE3aadxNwZGa+Dvg+cAFARBwOnAEcUa3zdxGxqG9pJUldm7XoM/PbwE93mndjZk5Xk5uA5dX9U4GJzPxFZv4QuA84uo95JUldipzDfzwSESPAtZl55C6W/StwRWZ+NSI+D2zKzK9Wyy4DbsjMr+1ivdXAaoDh4eGVExMTTE1NMTQ0VOf7GQhzdaeJuZqYCczVLXM92/j4+JbMHJt14FxemgOMAHfuYv6FwFXseML4AvD+juWXAe+abfu+vLI35pq7JmbKNFe3zPVszPHllT2/YSoiVgFvB46rdgjwIHBIx7DlwMO97kOSVF9PL6+MiBOA84FTMvPpjkXXAGdExJ4RcSiwAviv+jElSb2a9Yg+Ii4HWsDSiHgQuIj2q2z2BG6KCGiflz8nM++KiCuBu4Fp4NzM/PWgwkvzYWTtdQPb9prRac56nu1vv+Tkge1XLy6zFn1mvncXsy/bzfiLgYvrhJIk9Y/vjJWkwln0klQ4i16SCmfRS1LhLHpJKpxFL0mFs+glqXAWvSQVzqKXpMJZ9JJUOItekgpn0UtS4Sx6SSqcRS9JhbPoJalwFr0kFc6il6TCWfSSVDiLXpIKZ9FLUuEsekkqnEUvSYWz6CWpcBa9JBVu8UIHkOZiZO11tdZfMzrNWTW3Ib1QeUQvSYWbtegj4ksR8VhE3Nkx78CIuCki7q2+HlDNj4j4XETcFxF3RMQbBhlekjS7uRzRfwU4Yad5a4ENmbkC2FBNA5wIrKhuq4Ev9iemJKlXsxZ9Zn4b+OlOs08F1lf31wOndcz/x2zbBCyJiIP7FVaS1L3IzNkHRYwA12bmkdX0E5m5pGP545l5QERcC1ySmTdX8zcA52fm5l1sczXto36Gh4dXTkxMMDU1xdDQUB++rf4yV3cGkWvrQ0/WWn94b3j0mT6F6aPd5Rpdtv/8hunwYvrd6oeFyjU+Pr4lM8dmG9fvV93ELubt8pkkM9cB6wDGxsay1WoxOTlJq9Xqc6T6zNWdQeSq+4qZNaPTXLq1eS8y212u7We25jdMhxfT71Y/NDXXjF5fdfPozCmZ6utj1fwHgUM6xi0HHu49niSprl6L/hpgVXV/FXB1x/wPVq++OQZ4MjMfqZlRklTDrH/LRsTlQAtYGhEPAhcBlwBXRsTZwAPA6dXw64GTgPuAp4EPDSCzJKkLsxZ9Zr73eRYdt4uxCZxbN5QkqX98Z6wkFc6il6TCWfSSVDiLXpIKZ9FLUuEsekkqnEUvSYWz6CWpcBa9JBXOopekwln0klQ4i16SCmfRS1LhLHpJKpxFL0mFs+glqXAWvSQVzqKXpMJZ9JJUOItekgpn0UtS4Sx6SSrc4oUOoBeWkbXXzTpmzeg0Z81hnKT54RG9JBXOopekwln0klS4WkUfEX8eEXdFxJ0RcXlE7BURh0bErRFxb0RcERF79CusJKl7PRd9RCwDPgKMZeaRwCLgDODjwKczcwXwOHB2P4JKknpT99TNYmDviFgM7AM8AhwLfK1avh44reY+JEk1RGb2vnLEecDFwDPAjcB5wKbMPKxafghwQ3XEv/O6q4HVAMPDwysnJiaYmppiaGio5zyDYq4dtj705KxjhveGR5+ZhzBdaGIm2H2u0WX7z2+YDv7Od2ehco2Pj2/JzLHZxvX8OvqIOAA4FTgUeAL4Z+DEXQzd5TNJZq4D1gGMjY1lq9VicnKSVqvVa6SBMdcOc3l9/JrRaS7d2qy3aDQxE+w+1/YzW/MbpoO/891paq4ZdU7dvBX4YWb+ODN/BXwdeCOwpDqVA7AceLhmRklSDXWK/gHgmIjYJyICOA64G9gIvLsaswq4ul5ESVIdPRd9Zt5K+6Lrd4Ct1bbWAecDH42I+4CDgMv6kFOS1KNaJy0z8yLgop1m3w8cXWe7kqT+ad7VKUnA3D5AbhC2X3LyguxXg+NHIEhS4Sx6SSqcRS9JhbPoJalwFr0kFc6il6TCWfSSVDiLXpIKZ9FLUuEsekkqnEUvSYWz6CWpcBa9JBXOopekwln0klQ4i16SCmfRS1LhLHpJKpxFL0mFs+glqXAWvSQVzqKXpMJZ9JJUOItekgpn0UtS4WoVfUQsiYivRcT3ImJbRPx+RBwYETdFxL3V1wP6FVaS1L26R/SfBb6Rmb8N/A6wDVgLbMjMFcCGalqStEB6LvqI2A94C3AZQGb+MjOfAE4F1lfD1gOn1Q0pSepdnSP6VwE/Br4cEbdFxD9ExL7AcGY+AlB9fXkfckqSehSZ2duKEWPAJuBNmXlrRHwW+Bnw4cxc0jHu8cx8znn6iFgNrAYYHh5eOTExwdTUFENDQz3lGSRz7bD1oSdnHTO8Nzz6zDyE6UITM0Ezc40u29/f+S4tVK7x8fEtmTk227g6Rf8bwKbMHKmm30z7fPxhQCszH4mIg4HJzHzN7rY1NjaWmzdvZnJyklar1VOeQTLXDiNrr5t1zJrRaS7dunge0sxdEzNBM3Ntv+Rkf+e7tFC5ImJORd/zqZvM/B/gRxExU+LHAXcD1wCrqnmrgKt73Yckqb66hxIfBv4pIvYA7gc+RPvJ48qIOBt4ADi95j4kSTXUKvrMvB3Y1Z8Nx9XZriSpf3xnrCQVzqKXpMJZ9JJUOItekgpn0UtS4Sx6SSqcRS9JhbPoJalwFr0kFc6il6TCWfSSVDiLXpIKZ9FLUuEsekkqnEUvSYWz6CWpcBa9JBXOopekwln0klQ4i16SCmfRS1LhLHpJKpxFL0mFs+glqXAWvSQVzqKXpMLVLvqIWBQRt0XEtdX0oRFxa0TcGxFXRMQe9WNKknrVjyP684BtHdMfBz6dmSuAx4Gz+7APSVKPFtdZOSKWAycDFwMfjYgAjgXeVw1ZD/w18MU6+5E0f0bWXsea0WnOWnvdvO97+yUnz/s+XwzqHtF/BvgL4P+q6YOAJzJzupp+EFhWcx+SpBoiM3tbMeLtwEmZ+acR0QI+BnwIuCUzD6vGHAJcn5mju1h/NbAaYHh4eOXExARTU1MMDQ319p0MkLl22PrQk7OOGd4bHn1mHsJ0oYmZwFw7G122/26X+1h8tvHx8S2ZOTbbuDqnbt4EnBIRJwF7AfvRPsJfEhGLq6P65cDDu1o5M9cB6wDGxsay1WoxOTlJq9WqEWkwzLXDXP6cXzM6zaVba50V7LsmZgJz7Wz7ma3dLvex2JueT91k5gWZuTwzR4AzgH/PzDOBjcC7q2GrgKtrp5Qk9WwQT9nnAxMR8bfAbcBlA9jHi9pIdVS9UBfMJL2w9KXoM3MSmKzu3w8c3Y/tSpLq852xklQ4i16SCmfRS1LhLHpJKpxFL0mFs+glqXAWvSQVzqKXpMJZ9JJUOItekgpn0UtS4Sx6SSqcRS9JhbPoJalwFr0kFc6il6TCWfSSVDiLXpIKZ9FLUuEsekkqnEUvSYWz6CWpcBa9JBXOopekwln0klQ4i16SCtdz0UfEIRGxMSK2RcRdEXFeNf/AiLgpIu6tvh7Qv7iSpG7VOaKfBtZk5muBY4BzI+JwYC2wITNXABuqaUnSAum56DPzkcz8TnX/f4FtwDLgVGB9NWw9cFrdkJKk3vXlHH1EjABHAbcCw5n5CLSfDICX92MfkqTeRGbW20DEEPAt4OLM/HpEPJGZSzqWP56ZzzlPHxGrgdUAw8PDKycmJpiammJoaKhWnkFoWq6tDz0JwPDe8OgzCxxmF5qYq4mZwFw7G122/26XN+2xOGOhco2Pj2/JzLHZxtUq+oh4KXAt8M3M/FQ17x6glZmPRMTBwGRmvmZ32xkbG8vNmzczOTlJq9XqOc+gNC3XyNrrAFgzOs2lWxcvcJrnamKuJmYCc+1s+yUn73Z50x6LMxYqV0TMqejrvOomgMuAbTMlX7kGWFXdXwVc3es+JEn11XnKfhPwAWBrRNxezftL4BLgyog4G3gAOL1eRElSHT0XfWbeDMTzLD6u1+1KkvqreScHX0BmzpVLUpP5EQiSVDiLXpIKZ9FLUuEsekkqnEUvSYWz6CWpcBa9JBXOopekwvmGKUmNMdubENeMTnPWAN6oONuHqb3QeUQvSYWz6CWpcBa9JBXOopekwln0klQ4i16SCmfRS1LhLHpJKpxFL0mFs+glqXAWvSQV7gX/WTfz8R90D+rzNSQ1Q90eqdMR8/E5Ox7RS1LhLHpJKpxFL0mFs+glqXADK/qIOCEi7omI+yJi7aD2I0navYEUfUQsAr4AnAgcDrw3Ig4fxL4kSbs3qCP6o4H7MvP+zPwlMAGcOqB9SZJ2Y1BFvwz4Ucf0g9U8SdI8i8zs/0YjTgfelpl/VE1/ADg6Mz/cMWY1sLqafA1wD7AU+EnfA9Vnru40MVcTM4G5umWuZ3tlZr5stkGDemfsg8AhHdPLgYc7B2TmOmBd57yI2JyZYwPK1DNzdaeJuZqYCczVLXP1ZlCnbv4bWBERh0bEHsAZwDUD2pckaTcGckSfmdMR8WfAN4FFwJcy865B7EuStHsD+1CzzLweuL7L1dbNPmRBmKs7TczVxExgrm6ZqwcDuRgrSWoOPwJBkgo3L0U/28chRMRHI+LuiLgjIjZExCs7lv06Im6vbn29oFsz1ysi4saI2FaNGVnoXBEx3vFvdXtE/DwiTlvoXNWyT0TEXdW/1+ciIhqS6+MRcWd1e0+/Ms0x1zkRsbX6Wd3c+e7xiLigWu+eiHhbE3JFxEERsTEipiLi8/3MVDPX8RGxpVq2JSKObUiuozsei9+NiHf2M1dXMnOgN9oXY38AvArYA/gucPhOY8aBfar7fwJc0bFsqqG5JoHjq/tDM+MWOlfHmAOBnzYhF/BG4D+qbSwCbgFaDch1MnAT7WtV+wKbgf3mMdd+HfdPAb5R3T+8Gr8ncGi1nUUNyLUv8AfAOcDn+5GnT7mOAn6zun8k8FBDcu0DLK7uHww8NjM937f5OKKf9eMQMnNjZj5dTW6i/br7xuaqnrEXZ+ZN1bipjnELlmsn7wZuaEiuBPai/UDZE3gp8GgDch0OfCszpzPzKdoP4hPmMdfPOib3pf3vRDVuIjN/kZk/BO6rtreguTLzqcy8Gfh5n7L0K9dtmTnzPp27gL0iYs8G5Ho6M6er+Xux4+c77+aj6Lv9OISzgRs6pveKiM0RsamfpyFq5vot4ImI+HpE3BYRn4z2B7ktdK5OZwCX9ylTrVyZeQuwEXikun0zM7ctdC7axX5iROwTEUtpH/kf8rxrDiBXRJwbET8APgF8pJt1FyDXIPUr17uA2zLzF03IFRG/FxF3AVuBczqKf17NR9Hv6lzsLp/ZIuL9wBjwyY7Zr8j2O87eB3wmIl7dgFyLgTcDHwN+l/afdWc1INfM/IOBUdrvY+iXnnNFxGHAa2kfSS8Djo2Ityx0rsy8kfZLgP+T9pPiLUC/HohzypWZX8jMVwPnA3/VzboLkGuQaueKiCOAjwN/3JRcmXlrZh5BuycuiIi9+phtzuaj6Gf9OASAiHgrcCFwSuez8cyfZJl5P+3z4kc1INeDtI8a7q+eof8FeEMDcs34Q+CqzPxVnzLVzfVOYFN1imuK9hH1MQ3IRWZenJmvz8zjaT+o753PXB0mgJm/WLtdd75yDVKtXBGxHLgK+GBm/qApuWZUf8E+Rfsawvwb9EUA2ke/99O+qDRzMeOIncYcRfuCx4qd5h8A7FndX0r7QXh4A3Itqsa/rJr+MnDuQufqWL4JGG/Qz/E9wL9V23gpsAF4RwNyLQIOqu6/DriTPl0sm2OuFR333wFsru4fwbMvxt5P/y7G9pyrY95Z9P9ibJ1/ryXV+Hf1M1Mfch3Kjouxr6T9BLG03xnn9H3My07gJOD71YPtwmre39A+uqIqgUeB26vbNdX8N9I+t/Xd6uvZTchVLTseuKPK9RVgj4bkGgEeAl7SoJ/jIuDvgW3A3cCnGpJrryrP3bSfHF8/z7k+S/vi4e20r2Ec0bHuhdV69wAnNijXdtqv5pqifbTblwOvOrlonyp5quPnezvw8gbk+kDH/O8Ap/Xz59jNzXfGSlLhfGesJBXOopekwln0klQ4i16SCmfRS1LhLHpJKpxFL0mFs+glqXD/D8EH/6PEGsgxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.rf.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    500.000000\n",
       "mean       0.294388\n",
       "std        0.014050\n",
       "min        0.254138\n",
       "25%        0.285190\n",
       "50%        0.294705\n",
       "75%        0.303582\n",
       "max        0.330818\n",
       "Name: rf, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SECOND GRID SEARCH\n",
    "results.rf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2a13acf8>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.rf.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    500.000000\n",
       "mean       0.319360\n",
       "std        0.012050\n",
       "min        0.282213\n",
       "25%        0.311495\n",
       "50%        0.319391\n",
       "75%        0.327726\n",
       "max        0.356968\n",
       "Name: lr, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.lr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Hyperparamater Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "df = deepcopy(df.sample(len(df)).reset_index(drop = True))\n",
    "\n",
    "# set train/test\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 200, 300, 400, 500, 600, 700,\n",
    "                800, 900, 1000, 1500, 2000, 3000]                 # Number of trees in random forest\n",
    "max_features = ['auto', 'sqrt']                                   # Number of features to consider at every split\n",
    "max_depth = [None, 5, 10, 15, 20, 30, 40, 50, 60, 80, 100, 120]   # Maximum number of levels in tree\n",
    "min_samples_split = [2, 5, 10, 15, 20, 25]                        # Minimum number of samples required to split a node\n",
    "min_samples_leaf = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]        # Minimum number of samples required at each leaf node\n",
    "bootstrap = [True, False]                                         # Method of selecting samples for training each tree\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf      = RandomForestRegressor()\n",
    "rf_rand = RandomizedSearchCV(estimator = rf,\n",
    "                             param_distributions = random_grid,\n",
    "                             n_iter = 2500,\n",
    "                             cv = 5,\n",
    "                             verbose = 2,\n",
    "                             random_state = SEED,\n",
    "                             n_jobs = -1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rand.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=5, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rand.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "df = deepcopy(df.sample(len(df)).reset_index(drop = True))\n",
    "\n",
    "# set train/test\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_features': ['sqrt'],\n",
    "    'max_depth': [16, 18, 20, 22, 24], # 20\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8], # 5\n",
    "    'min_samples_split': [2, 3, 4], # 2\n",
    "    'n_estimators': [260, 270, 280, 290, 300, 310, 320, 330, 340], # 300\n",
    "}\n",
    "# init model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# init grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = rf,\n",
    "    param_grid = param_grid,\n",
    "    cv = 10,\n",
    "    n_jobs = -1,\n",
    "    verbose = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=24,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=3, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=290, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "df = deepcopy(df.sample(len(df)).reset_index(drop = True))\n",
    "\n",
    "# set train/test\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_features': ['sqrt'],\n",
    "    'max_depth': [22, 23, 24, 25, 26], # 24\n",
    "    'min_samples_leaf': [2, 3, 4], # 3\n",
    "    'min_samples_split': [2], # 2\n",
    "    'n_estimators': [280, 285, 290, 295, 300], # 290\n",
    "}\n",
    "# init model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# init grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = rf,\n",
    "    param_grid = param_grid,\n",
    "    cv = 10,\n",
    "    n_jobs = -1,\n",
    "    verbose = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=22,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=3, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=295, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Feature Importance & Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = []\n",
    "\n",
    "for _ in range(250):\n",
    "    \n",
    "    print(_)\n",
    "    \n",
    "    # shuffle data\n",
    "    df = deepcopy(df.sample(len(df)).reset_index(drop = True))\n",
    "    \n",
    "    # set X and y\n",
    "    X = df.iloc[:,:-1].values\n",
    "    y = df.iloc[:,-1].values\n",
    "\n",
    "    # the crawl embeddings tend to score higher in general\n",
    "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    scaled_X = scaler.fit_transform(X)\n",
    "    \n",
    "    # init & fit\n",
    "    rf = RandomForestRegressor(\n",
    "        bootstrap = True,\n",
    "        max_depth = 24,\n",
    "        max_features = 'sqrt',\n",
    "        max_leaf_nodes = None,\n",
    "        min_impurity_decrease = 0.0,\n",
    "        min_impurity_split = None,\n",
    "        min_samples_leaf = 3,\n",
    "        min_samples_split = 2,\n",
    "        min_weight_fraction_leaf = 0.0,\n",
    "        n_estimators = 290,\n",
    "        random_state = SEED,\n",
    "    )\n",
    "    rf.fit(scaled_X, y)\n",
    "    \n",
    "    # save\n",
    "    imp.append(deepcopy(rf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame(imp, columns = df.columns[:-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ft_wiki_overall_avg_avg_similarity            0.091070\n",
       "ft_wiki_overall_similarity                    0.088761\n",
       "avg_all                                       0.077965\n",
       "ft_wiki_avg_token_max_similarity              0.072831\n",
       "ft_wiki_max_token_max_similarity              0.064898\n",
       "ft_wiki_overall_avg_max_similarity            0.064355\n",
       "use_overall_similarity                        0.038384\n",
       "use_dan_overall_avg_avg_similarity            0.033374\n",
       "use_transformer_overall_avg_max_similarity    0.030428\n",
       "use_transformer_overall_avg_avg_similarity    0.028534\n",
       "use_transformer_overall_similarity            0.026824\n",
       "ft_crawl_overall_similarity                   0.026218\n",
       "use_dan_overall_similarity                    0.024760\n",
       "use_dan_overall_avg_max_similarity            0.022077\n",
       "ft_crawl_overall_avg_max_similarity           0.020009\n",
       "ft_crawl_overall_avg_avg_similarity           0.019369\n",
       "ft_crawl_max_token_max_similarity             0.017591\n",
       "ft_crawl_avg_token_max_similarity             0.016278\n",
       "glove_max_token_max_similarity                0.012846\n",
       "ft_wiki_avg_pln_similarity                    0.012089\n",
       "glove_avg_token_max_similarity                0.011700\n",
       "use_dan_avg_pln_similarity                    0.011013\n",
       "use_transformer_avg_token_max_similarity      0.010721\n",
       "glove_overall_avg_avg_similarity              0.010547\n",
       "use_transformer_max_token_max_similarity      0.010237\n",
       "ft_wiki_max_pln_similarity                    0.010059\n",
       "glove_avg_pln_similarity                      0.010046\n",
       "use_dan_max_pln_similarity                    0.009890\n",
       "use_transformer_avg_pln_similarity            0.009877\n",
       "use_transformer_max_pln_similarity            0.009848\n",
       "glove_overall_avg_max_similarity              0.009418\n",
       "glove_overall_similarity                      0.008841\n",
       "bert_avg_pln_similarity                       0.008541\n",
       "glove_max_pln_similarity                      0.008257\n",
       "bert_max_token_max_similarity                 0.007613\n",
       "bert_max_pln_similarity                       0.007559\n",
       "bert_avg_token_max_similarity                 0.007379\n",
       "bert_overall_avg_avg_similarity               0.007329\n",
       "ft_crawl_avg_pln_similarity                   0.007329\n",
       "ft_crawl_max_pln_similarity                   0.007258\n",
       "bert_overall_similarity                       0.007192\n",
       "bert_overall_avg_max_similarity               0.007041\n",
       "use_dan_max_token_max_similarity              0.006856\n",
       "use_dan_avg_token_max_similarity              0.006788\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.mean().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = []\n",
    "\n",
    "for _ in range(250):\n",
    "    \n",
    "    print(_)\n",
    "    \n",
    "    # shuffle data\n",
    "    df = deepcopy(df.sample(len(df)).reset_index(drop = True))\n",
    "    \n",
    "    # set X and y\n",
    "    X = df.iloc[:,:-1].values\n",
    "    y = df.iloc[:,-1].values\n",
    "\n",
    "    # the crawl embeddings tend to score higher in general\n",
    "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    scaled_X = scaler.fit_transform(X)\n",
    "    \n",
    "    # fit model\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(scaled_X, y);\n",
    "    \n",
    "    # save\n",
    "    coef.append(deepcopy(lr.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bert_overall_avg_max_similarity               117.356511\n",
       "bert_overall_similarity                        45.243495\n",
       "avg_all                                        15.504321\n",
       "use_transformer_avg_pln_similarity              5.726846\n",
       "use_transformer_avg_token_max_similarity        5.089262\n",
       "ft_wiki_overall_similarity                      4.546034\n",
       "use_transformer_max_pln_similarity              4.071484\n",
       "ft_wiki_avg_token_max_similarity                3.690495\n",
       "ft_wiki_avg_pln_similarity                      3.690495\n",
       "use_transformer_max_token_max_similarity        3.618196\n",
       "use_dan_max_pln_similarity                      2.336751\n",
       "use_dan_max_token_max_similarity                2.336751\n",
       "glove_overall_avg_max_similarity                2.223537\n",
       "use_dan_overall_avg_avg_similarity              1.897487\n",
       "ft_crawl_overall_similarity                     1.412537\n",
       "ft_crawl_max_pln_similarity                     1.211309\n",
       "ft_crawl_max_token_max_similarity               1.177286\n",
       "use_dan_avg_pln_similarity                      0.781312\n",
       "use_dan_avg_token_max_similarity                0.781312\n",
       "glove_avg_pln_similarity                        0.603866\n",
       "glove_avg_token_max_similarity                  0.571371\n",
       "glove_overall_avg_avg_similarity                0.023526\n",
       "ft_wiki_max_pln_similarity                     -0.507822\n",
       "ft_wiki_max_token_max_similarity               -0.507822\n",
       "glove_max_token_max_similarity                 -0.528635\n",
       "ft_crawl_overall_avg_avg_similarity            -0.547335\n",
       "glove_max_pln_similarity                       -0.558699\n",
       "ft_crawl_avg_token_max_similarity              -0.685522\n",
       "ft_crawl_avg_pln_similarity                    -0.710139\n",
       "ft_wiki_overall_avg_max_similarity             -2.656086\n",
       "use_transformer_overall_avg_max_similarity     -3.128943\n",
       "use_dan_overall_avg_max_similarity             -3.533050\n",
       "use_transformer_overall_avg_avg_similarity     -3.975625\n",
       "use_overall_similarity                         -4.152576\n",
       "ft_crawl_overall_avg_max_similarity            -4.226535\n",
       "glove_overall_similarity                       -4.815655\n",
       "use_dan_overall_similarity                     -4.867751\n",
       "bert_avg_token_max_similarity                  -6.064608\n",
       "bert_avg_pln_similarity                        -6.642604\n",
       "use_transformer_overall_similarity            -10.585182\n",
       "ft_wiki_overall_avg_avg_similarity            -11.052721\n",
       "bert_overall_avg_avg_similarity               -13.596559\n",
       "bert_max_token_max_similarity                 -71.541062\n",
       "bert_max_pln_similarity                       -78.359388\n",
       "dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = pd.DataFrame(coef, columns = df.columns[:-1].tolist())\n",
    "coefs.mean().sort_values(ascending = False) / 1e10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use RF Model to Predict on Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "all_plns = deepcopy(pd.read_feather('final_full_standardized_uniq_plns_with_labels'\n",
    "                                   ).drop(['track_id', 'score'], axis = 1))\n",
    "\n",
    "# load labeled data\n",
    "df = pd.read_feather('final_full_standardized_uniq_plns_with_labels').dropna()\n",
    "df.drop(['query', 'track_id', 'playlist_name', 'search_rank'], axis = 1, inplace = True)\n",
    "df = df[[col for col in df.columns if col != 'score'] + ['score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "test_X = all_plns.iloc[:,3:].values\n",
    "\n",
    "for i in range(250):\n",
    "    \n",
    "    print(f'Iter: {i}')\n",
    "    \n",
    "    # shuffle data\n",
    "    df = deepcopy(df.sample(len(df)).reset_index(drop = True))\n",
    "    \n",
    "    # set X and y\n",
    "    X = df.iloc[:,:-1].values\n",
    "    y = df.iloc[:,-1].values\n",
    "    \n",
    "    # Best RF Model\n",
    "    rf = RandomForestRegressor(\n",
    "        bootstrap = True,\n",
    "        max_depth = 24,\n",
    "        max_features = 'sqrt',\n",
    "        max_leaf_nodes = None,\n",
    "        min_impurity_decrease = 0.0,\n",
    "        min_impurity_split = None,\n",
    "        min_samples_leaf = 3,\n",
    "        min_samples_split = 2,\n",
    "        min_weight_fraction_leaf = 0.0,\n",
    "        n_estimators = 290,\n",
    "    )\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # save\n",
    "    preds.append(deepcopy(rf.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to pln data\n",
    "df = pd.DataFrame(np.array(preds).T)\n",
    "avg_preds = df.mean(1)\n",
    "all_plns['rf_similarity'] = avg_preds.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plns.reset_index(drop = True).to_feather('FINAL_uniq_plns_with_rf_similarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>search_rank</th>\n",
       "      <th>rf_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>884012</th>\n",
       "      <td>breakfast</td>\n",
       "      <td>mac tonight</td>\n",
       "      <td>101</td>\n",
       "      <td>0.714643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767503</th>\n",
       "      <td>korea OR korean OR south korea OR 대한민국 OR 한국어</td>\n",
       "      <td>south szn</td>\n",
       "      <td>6015</td>\n",
       "      <td>0.653743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362582</th>\n",
       "      <td>indian classical OR classical indian</td>\n",
       "      <td>feathered indians</td>\n",
       "      <td>6736</td>\n",
       "      <td>0.565209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528129</th>\n",
       "      <td>sexual</td>\n",
       "      <td>tumblr deleted porn</td>\n",
       "      <td>1614</td>\n",
       "      <td>0.530899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986325</th>\n",
       "      <td>happiness</td>\n",
       "      <td>ti ho portato un pacco happy birthday</td>\n",
       "      <td>573</td>\n",
       "      <td>0.527008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028271</th>\n",
       "      <td>rhythm</td>\n",
       "      <td>lactic acid run 175 bpm</td>\n",
       "      <td>19</td>\n",
       "      <td>0.472443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873530</th>\n",
       "      <td>all time</td>\n",
       "      <td>beat house</td>\n",
       "      <td>852</td>\n",
       "      <td>0.466805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451982</th>\n",
       "      <td>going out</td>\n",
       "      <td>it s gonna be a good one</td>\n",
       "      <td>1457</td>\n",
       "      <td>0.464573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072388</th>\n",
       "      <td>90s OR nineties</td>\n",
       "      <td>soir e ann e 90 2000</td>\n",
       "      <td>3889</td>\n",
       "      <td>0.426075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479552</th>\n",
       "      <td>out of this world</td>\n",
       "      <td>teatro essential playlist</td>\n",
       "      <td>488</td>\n",
       "      <td>0.392410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763941</th>\n",
       "      <td>korea OR korean OR south korea OR 대한민국 OR 한국어</td>\n",
       "      <td>down south hip hop old school</td>\n",
       "      <td>2302</td>\n",
       "      <td>0.360972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389572</th>\n",
       "      <td>icy</td>\n",
       "      <td>c est mega cool ici</td>\n",
       "      <td>1625</td>\n",
       "      <td>0.358016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405054</th>\n",
       "      <td>kaleidoscope</td>\n",
       "      <td>bach switched on</td>\n",
       "      <td>2</td>\n",
       "      <td>0.284657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921492</th>\n",
       "      <td>iceland OR icelandic OR ísland OR íslensku</td>\n",
       "      <td>monkey island songs and themes</td>\n",
       "      <td>391</td>\n",
       "      <td>0.235010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153440</th>\n",
       "      <td>acoustic</td>\n",
       "      <td>chill out</td>\n",
       "      <td>380</td>\n",
       "      <td>0.213505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355559</th>\n",
       "      <td>gloomy</td>\n",
       "      <td>dec</td>\n",
       "      <td>1023</td>\n",
       "      <td>0.152989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364971</th>\n",
       "      <td>indian classical OR classical indian</td>\n",
       "      <td>flying carpet</td>\n",
       "      <td>9136</td>\n",
       "      <td>0.150922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006748</th>\n",
       "      <td>mesmerize OR mesmerized</td>\n",
       "      <td>r and b fresh</td>\n",
       "      <td>3</td>\n",
       "      <td>0.146238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619167</th>\n",
       "      <td>theatrical</td>\n",
       "      <td>evening bliss</td>\n",
       "      <td>416</td>\n",
       "      <td>0.124316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141733</th>\n",
       "      <td>fusion</td>\n",
       "      <td>best of bollywood</td>\n",
       "      <td>484</td>\n",
       "      <td>0.086120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 query  \\\n",
       "884012                                       breakfast   \n",
       "767503   korea OR korean OR south korea OR 대한민국 OR 한국어   \n",
       "1362582           indian classical OR classical indian   \n",
       "528129                                          sexual   \n",
       "986325                                       happiness   \n",
       "1028271                                         rhythm   \n",
       "873530                                        all time   \n",
       "451982                                       going out   \n",
       "1072388                                90s OR nineties   \n",
       "479552                               out of this world   \n",
       "763941   korea OR korean OR south korea OR 대한민국 OR 한국어   \n",
       "389572                                             icy   \n",
       "405054                                    kaleidoscope   \n",
       "921492      iceland OR icelandic OR ísland OR íslensku   \n",
       "1153440                                       acoustic   \n",
       "355559                                          gloomy   \n",
       "1364971           indian classical OR classical indian   \n",
       "1006748                        mesmerize OR mesmerized   \n",
       "619167                                      theatrical   \n",
       "1141733                                         fusion   \n",
       "\n",
       "                                 playlist_name  search_rank  rf_similarity  \n",
       "884012                             mac tonight          101       0.714643  \n",
       "767503                               south szn         6015       0.653743  \n",
       "1362582                      feathered indians         6736       0.565209  \n",
       "528129                     tumblr deleted porn         1614       0.530899  \n",
       "986325   ti ho portato un pacco happy birthday          573       0.527008  \n",
       "1028271                lactic acid run 175 bpm           19       0.472443  \n",
       "873530                              beat house          852       0.466805  \n",
       "451982                it s gonna be a good one         1457       0.464573  \n",
       "1072388                   soir e ann e 90 2000         3889       0.426075  \n",
       "479552               teatro essential playlist          488       0.392410  \n",
       "763941           down south hip hop old school         2302       0.360972  \n",
       "389572                     c est mega cool ici         1625       0.358016  \n",
       "405054                        bach switched on            2       0.284657  \n",
       "921492          monkey island songs and themes          391       0.235010  \n",
       "1153440                              chill out          380       0.213505  \n",
       "355559                                     dec         1023       0.152989  \n",
       "1364971                          flying carpet         9136       0.150922  \n",
       "1006748                          r and b fresh            3       0.146238  \n",
       "619167                           evening bliss          416       0.124316  \n",
       "1141733                      best of bollywood          484       0.086120  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_plns[all_plns.rf_similarity < (all_plns.rf_similarity.mean() - (all_plns.rf_similarity.std() * 1))][\n",
    "    ['query', 'playlist_name', 'search_rank', 'rf_similarity']\n",
    "].sample(20).sort_values('rf_similarity', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>search_rank</th>\n",
       "      <th>rf_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1028256</th>\n",
       "      <td>rhythm</td>\n",
       "      <td>sexy as folk</td>\n",
       "      <td>4</td>\n",
       "      <td>0.649524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291365</th>\n",
       "      <td>earthy</td>\n",
       "      <td>petrichor</td>\n",
       "      <td>96</td>\n",
       "      <td>0.649023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072531</th>\n",
       "      <td>90s OR nineties</td>\n",
       "      <td>punk 90 s</td>\n",
       "      <td>4036</td>\n",
       "      <td>0.641092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053924</th>\n",
       "      <td>00s OR 2000s</td>\n",
       "      <td>smash hits 2000 present</td>\n",
       "      <td>1728</td>\n",
       "      <td>0.640569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781144</th>\n",
       "      <td>south america OR sudamerica</td>\n",
       "      <td>anywhere south of 49th st</td>\n",
       "      <td>927</td>\n",
       "      <td>0.640217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273900</th>\n",
       "      <td>progressive house</td>\n",
       "      <td>electric sheep</td>\n",
       "      <td>1031</td>\n",
       "      <td>0.634916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063572</th>\n",
       "      <td>70s OR seventies</td>\n",
       "      <td>anni 60 70 italiani compilation roberto</td>\n",
       "      <td>1711</td>\n",
       "      <td>0.633367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262849</th>\n",
       "      <td>oriental</td>\n",
       "      <td>se oriente</td>\n",
       "      <td>1466</td>\n",
       "      <td>0.632096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972617</th>\n",
       "      <td>feeling blue OR feeling sad OR feeling bad OR ...</td>\n",
       "      <td>lonny s rainy day</td>\n",
       "      <td>445</td>\n",
       "      <td>0.630560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435417</th>\n",
       "      <td>clubbing</td>\n",
       "      <td>50cent 50 cent in the club dirty in da club</td>\n",
       "      <td>407</td>\n",
       "      <td>0.625797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613354</th>\n",
       "      <td>tender</td>\n",
       "      <td>a little bit of tlc</td>\n",
       "      <td>429</td>\n",
       "      <td>0.621793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200371</th>\n",
       "      <td>breakup</td>\n",
       "      <td>ahhhhhhhhhhhhhhh im so sad fuck</td>\n",
       "      <td>7172</td>\n",
       "      <td>0.621645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832125</th>\n",
       "      <td>argentina OR argentinian</td>\n",
       "      <td>asadito</td>\n",
       "      <td>64</td>\n",
       "      <td>0.620755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054409</th>\n",
       "      <td>00s OR 2000s</td>\n",
       "      <td>movidos 2000 2017</td>\n",
       "      <td>2225</td>\n",
       "      <td>0.617027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206484</th>\n",
       "      <td>experimental</td>\n",
       "      <td>ambient arrivals discover fresh new ambient re...</td>\n",
       "      <td>622</td>\n",
       "      <td>0.611415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490111</th>\n",
       "      <td>pleasant</td>\n",
       "      <td>wakeup and chill</td>\n",
       "      <td>801</td>\n",
       "      <td>0.609320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179316</th>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>r and b lounge</td>\n",
       "      <td>987</td>\n",
       "      <td>0.606658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782702</th>\n",
       "      <td>south america OR sudamerica</td>\n",
       "      <td>south island roadie</td>\n",
       "      <td>2504</td>\n",
       "      <td>0.605664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585154</th>\n",
       "      <td>spooky</td>\n",
       "      <td>phat bangers</td>\n",
       "      <td>173</td>\n",
       "      <td>0.605364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677510</th>\n",
       "      <td>german</td>\n",
       "      <td>deutschrap</td>\n",
       "      <td>1598</td>\n",
       "      <td>0.604504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     query  \\\n",
       "1028256                                             rhythm   \n",
       "291365                                              earthy   \n",
       "1072531                                    90s OR nineties   \n",
       "1053924                                       00s OR 2000s   \n",
       "781144                         south america OR sudamerica   \n",
       "273900                                   progressive house   \n",
       "1063572                                   70s OR seventies   \n",
       "1262849                                           oriental   \n",
       "972617   feeling blue OR feeling sad OR feeling bad OR ...   \n",
       "435417                                            clubbing   \n",
       "613354                                              tender   \n",
       "1200371                                            breakup   \n",
       "832125                            argentina OR argentinian   \n",
       "1054409                                       00s OR 2000s   \n",
       "206484                                        experimental   \n",
       "490111                                            pleasant   \n",
       "179316                                                 r&b   \n",
       "782702                         south america OR sudamerica   \n",
       "585154                                              spooky   \n",
       "677510                                              german   \n",
       "\n",
       "                                             playlist_name  search_rank  \\\n",
       "1028256                                       sexy as folk            4   \n",
       "291365                                           petrichor           96   \n",
       "1072531                                          punk 90 s         4036   \n",
       "1053924                            smash hits 2000 present         1728   \n",
       "781144                           anywhere south of 49th st          927   \n",
       "273900                                      electric sheep         1031   \n",
       "1063572            anni 60 70 italiani compilation roberto         1711   \n",
       "1262849                                         se oriente         1466   \n",
       "972617                                   lonny s rainy day          445   \n",
       "435417         50cent 50 cent in the club dirty in da club          407   \n",
       "613354                                 a little bit of tlc          429   \n",
       "1200371                    ahhhhhhhhhhhhhhh im so sad fuck         7172   \n",
       "832125                                             asadito           64   \n",
       "1054409                                  movidos 2000 2017         2225   \n",
       "206484   ambient arrivals discover fresh new ambient re...          622   \n",
       "490111                                    wakeup and chill          801   \n",
       "179316                                      r and b lounge          987   \n",
       "782702                                 south island roadie         2504   \n",
       "585154                                        phat bangers          173   \n",
       "677510                                          deutschrap         1598   \n",
       "\n",
       "         rf_similarity  \n",
       "1028256       0.649524  \n",
       "291365        0.649023  \n",
       "1072531       0.641092  \n",
       "1053924       0.640569  \n",
       "781144        0.640217  \n",
       "273900        0.634916  \n",
       "1063572       0.633367  \n",
       "1262849       0.632096  \n",
       "972617        0.630560  \n",
       "435417        0.625797  \n",
       "613354        0.621793  \n",
       "1200371       0.621645  \n",
       "832125        0.620755  \n",
       "1054409       0.617027  \n",
       "206484        0.611415  \n",
       "490111        0.609320  \n",
       "179316        0.606658  \n",
       "782702        0.605664  \n",
       "585154        0.605364  \n",
       "677510        0.604504  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_plns[(all_plns.rf_similarity < 0.65) & (all_plns.rf_similarity > 0.60)][\n",
    "    ['query', 'playlist_name', 'search_rank', 'rf_similarity']\n",
    "].sample(20).sort_values('rf_similarity', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08513400075171937"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_plns[all_plns.rf_similarity < 0.65]) / len(all_plns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "After some brief analysis, it seems that 0.65 would be a good similarity score threshold. I still keep ~91% of data and if I want to do aditional, more strict filtering, I can do it after all of the other cleaning steps have been processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
